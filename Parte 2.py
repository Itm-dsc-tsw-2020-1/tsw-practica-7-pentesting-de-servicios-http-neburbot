import sys
import requests as req
from bs4 import BeautifulSoup
import mysql.connector as mysql

def scraping(host):
    try:
        url = req.get('http://' + str(host))        
        if str(url.status_code) == "200":
            print("Conexi贸n establecida con: "+ host)
            s = BeautifulSoup(url.text, 'html.parser')
            print("Etiquetas del form: ")
            print(s.form)
            print("Enlaces encontrados: ")
            array = s.find_all('a')
            for index in array:
                print(index['href'])
                cursor.execute("INSERT INTO enlace (direccion) VALUES ('" + index['href'] + "')")
                conexion.commit()
        else:
            print("Error al establecer conexi贸n con: "+ host)
    except:
        print("Error:", sys.exc_info()[0])
        
def enlaces(host):
    try:
        if "http://" in host or "https://" in host:
            url = req.get(str(host))
        else:
            url = req.get('http://'+ str(host))                    
        if str(url.status_code) == "200":
            print("Conexi贸n establecida con: "+ host)
            s = BeautifulSoup(url.text, 'html.parser')
            print("Etiquetas del form: ")
            print(s.form)
        else:
            print("Error al establecer conexi贸n con: "+ host)
    except:
        print("Error:", sys.exc_info()[0])
        

conexion = mysql.connect( host = 'localhost', user = 'root', passwd = '', db = 'nmap' )
operacion = conexion.cursor()
operacion.execute( "SELECT direccion FROM puerto WHERE servicio = 'http';")
for ip in operacion.fetchall() :
    scraping(ip[0]) 
operacion.execute( "SELECT direccion FROM enlace;")
for direccion in operacion.fetchall() :
    enlaces(direccion[0]) 
conexion.close()